[
    {
        "title": "Google Is Giving Away Some of the A.I. That Powers Chatbots",
        "highlights": "['Now, in an indication that critics of sharing A.I. technology are losing ground to their industry peers, Google is making a similar move. Google released the computer code that powers its online chatbot on Wednesday, after keeping this kind of technology concealed for many months. Much like Meta, Google said the benefits of freely sharing the technology \u2014 called a large language model \u2014 outweighed the potential risks. The company said in a blog post that it was releasing two A.I.']",
        "text": "                                Advertisement  SKIP ADVERTISEMENT    You have a preview view of this article while we are checking your access. When we have confirmed access, the full article content will load.   Like Meta, the company opened access to its technology to outside programmers, but kept its most powerful system under wraps.           and  Cade Metz writes about artificial intelligence and Nico Grant about Google, both from San Francisco.    Feb. 21, 2024,       When Meta shared the raw computer code needed to build a chatbot last year, rival companies said Meta was releasing poorly understood and perhaps even dangerous technology into the world. Now, in an indication that critics of sharing A.I. technology are losing ground to their industry peers, Google is making a similar move. Google released the computer code that powers its online chatbot on Wednesday, after keeping this kind of technology concealed for many months. Much like Meta, Google said the benefits of freely ",
        "url": "https://www.nytimes.com/2024/02/21/technology/google-open-source-ai.html"
    },
    {
        "title": "Scientists Are Putting ChatGPT Brains Inside Robot Bodies. What Could Possibly Go Wrong?",
        "highlights": "[\"Because its response is only a prediction about how words combine, the program doesn't really understand what it is saying. But people do. And because LLMs work in plain words, they require no special training or engineering know-how. Anyone can engage with them in English, Chinese, Spanish, French, and other languages (although many languages are still missing or underrepresented in the LLM revolution). When you give an LLM a prompt\u2014a question, request or instruction\u2014the model converts your words into numbers, the mathematical representations of their relations to one another.\"]",
        "text": "  n restaurants around the world, from Shanghai to New York, robots are cooking meals. They make burgers and dosas, pizzas and stir-fries, in much the same way robots have made other things for the past 50 years: by following instructions precisely, doing the same steps in the same way, over and over. But Ishika Singh wants to build a robot that can make dinner\u2014one that can go into a kitchen, riffle through the fridge and cabinets, pull out ingredients that will coalesce into a tasty dish or two, then set the table. It's so easy that a child can do it. Yet no robot can. It takes too much knowledge about that one kitchen\u2014and too much common sense and flexibility and resourcefulness\u2014for robot programming to capture. The problem, says Singh, a Ph.D. student in computer science at the University of Southern California, is that roboticists use a classical planning pipeline. \u201cThey formally define every action and its preconditions and predict its effect,\u201d she says. \u201cIt specifies everything t",
        "url": "https://www.scientificamerican.com/article/scientists-are-putting-chatgpt-brains-inside-robot-bodies-what-could-possibly-go-wrong/"
    },
    {
        "title": "China\u2019s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. Technology",
        "highlights": "['system as an alternative to options like Meta\u2019s generative A.I. model, called LLaMA. There was just one twist: Some of the technology in 01.AI\u2019s system came from LLaMA. Mr. Lee\u2019s start-up then built on Meta\u2019s technology, training its system with new data to make it more powerful. The situation is emblematic of a reality that many in China openly admit.']",
        "text": "                                Advertisement  SKIP ADVERTISEMENT    You have a preview view of this article while we are checking your access. When we have confirmed access, the full article content will load.   China\u2019s tech firms were caught off guard by breakthroughs in generative artificial intelligence. Beijing\u2019s regulations and a sagging economy aren\u2019t helping.           and  The reporters interviewed more than a dozen A.I. experts about China\u2019s competitiveness in the critical field.           In November, a year after ChatGPT\u2019s release, a relatively unknown Chinese start-up leaped to the top of a leaderboard that judged the abilities of open-source artificial intelligence systems. The Chinese firm, 01.AI, was only eight months old but had deep-pocketed backers and a $1 billion valuation and was founded by a well-known investor and technologist, Kai-Fu Lee. In interviews, Mr. Lee presented his A.I. system as an alternative to options like Meta\u2019s generative A.I. model, called LLaM",
        "url": "https://www.nytimes.com/2024/02/21/technology/china-united-states-artificial-intelligence.html"
    },
    {
        "title": "Air Canada chatbot error underscores AI\u2019s enterprise liability danger",
        "highlights": "['In the Air Canada case, Christopher Rivers, a member of the British Columbia Civil Resolution Tribunal, sided with Moffatt and rejected the airline\u2019s assertion that the chatbot is \u201ca separate legal entity that is responsible for its own actions.\u201d Air Canada could not explain why the information on bereavement discounts on its website was more reliable than what was provided by the chatbot, Rivers wrote in his Feb. 14 ruling. \u201cAir Canada owed Mr. Moffatt a duty of care,\u201d he added. \"Generally, the applicable standard of care requires a company to take reasonable care to ensure their representations are accurate and not misleading.\u201d Three analysts who focus on the AI market agreed that companies using chatbots and other AI tools need to check their output. About 30% of genAI answers are fictional, an output called a \u201challucination,\u201d Litan said. \u201cCompanies using chatbots must use guardrails that highlight output anomalies such as hallucinations, inaccurate, and illegal information \u2014 and set up human review operations that investigate and block or approve these outputs before they are disseminated,\u201d she said.']",
        "text": " \n\n\n\nThe Canadian airline has been ordered to pay for a pricing mistake by a customer-service chatbot, highlighting why companies must invest in monitoring their AI tools, analysts say.\n\n\n\n\tSenior Editor, \n\t\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nA civil tribunal in Canada has ordered Air Canada to pay for a mistake made by a customer-service chatbot, highlighting the need for companies to better train and monitor their artificial intelligence (AI) tools. British Columbia resident Jake Moffatt visited Air Canada\u2019s website in November 2022 to book a flight for his grandmother\u2019s funeral in Ontario. The website\u2019s chatbot told him he could be refunded a portion of the next-day ticket and the return ticket, if he applied for the discount within 90 days. That information was incorrect; Air Canada\u2019s policy, available on its website, is to provide bereavement discounts if the customer applies in advance. After Air Canada refused to provide the discount, a Canadian tribunal ordered the airline to pay about $600 in ber",
        "url": "https://www.computerworld.com/article/3713100/air-canada-chatbot-error-underscores-ais-enterprise-liability-danger.html?utm_campaign=organic&utm_content=content&utm_source=twitter&utm_medium=social#tk.rss_all"
    },
    {
        "title": "First there were AI chatbots. Now AI assistants can order Ubers and book vacations",
        "highlights": "['To work, the Rabbit R1 has to be connected to Wi-Fi, but there is also a SIM card slot, in case people want to buy a separate data plan just for the gadget. When asked why anyone would want to carry around a separate device just to do something your smartphone could do in 30 seconds, Rabbit spokesman Ryan Fenwick argued that using apps to place orders and make requests all day takes longer than we might imagine. \"We are looking at the entire process, end to end, to automate as much as possible and make these complex actions much quicker and much more intuitive than what\\'s currently possible with multiple apps on a smartphone,\" Fenwick said. Is this device necessary? ChatGPT\\'s introduction in late 2022 set off a frenzy at companies in many industries trying to ride the latest tech industry wave.']",
        "text": " \n\n\n\n\n\n\n The AI-powered Rabbit R1 device is seen at Rabbit Inc.'s headquarters in Santa Monica, California. The gadget is meant to serve as a personal assistant fulfilling tasks such as ordering food on DoorDash for you, calling an Uber or booking your family's vacation.\n \n \n Stella Kalinina for NPR\n \n \n hide caption \n\n  toggle caption \n \n\n \n\n\n\nThe AI-powered Rabbit R1 device is seen at Rabbit Inc.'s headquarters in Santa Monica, California. The gadget is meant to serve as a personal assistant fulfilling tasks such as ordering food on DoorDash for you, calling an Uber or booking your family's vacation.\n\n \n\nChatGPT can give you travel ideas, but it won't book your flight to Canc\u00fan. Now, artificial intelligence is here to help us scratch items off our to-do lists.   A slate of tech startups are developing products that use AI to complete real-world tasks. Silicon Valley watchers see this new crop of \"AI agents\" as being the next phase of the generative AI craze that took hold with the la",
        "url": "https://www.npr.org/2024/02/21/1232561606/ai-assistant-agent-rabbit"
    }
]